{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06adee88-e8d5-4e25-b608-48646a6dbabc",
   "metadata": {},
   "source": [
    "### 1. Importing Packages and Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3feec20-9b4c-4f36-b2b7-3797517c9280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    " \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc2834a-61ce-4745-aa9c-ec5c092453f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './iranian+churn+dataset.zip'\n",
    "\n",
    "with ZipFile(file_path) as z:\n",
    "    print(z.namelist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ad6973-2856-47e7-82dc-630131d84432",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = z.namelist()[0]\n",
    "with ZipFile(file_path).open(filename) as f:\n",
    "    df = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235ffa11-c598-40ad-b900-c20aae3cb73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18300b6a-ae41-462a-ba3b-25cef413ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Age'], inplace=True) # Drop duplicate feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127a274a-b757-4d8b-b32e-22fda4c1719b",
   "metadata": {},
   "source": [
    "### 2. Splitting Data into Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f602f7b-a46b-4a65-958c-fc49901b54d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use stratified split\n",
    "X = df.drop(columns = ['Churn']) # dataframe\n",
    "y = df['Churn'] # series\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=312, stratify=y)\n",
    "\n",
    "# Reset Index\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f'# of train samples: {len(X_train)}')\n",
    "print(f'# of test samples: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a2a4bc-5b28-4f85-9c39-38c5d96feb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0423d790-b18b-4000-bd40-d67f8d450f59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63053ca-0a92-40da-89b5-ec0746f04947",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [c for c in X_train.columns if X_train[c].nunique() < 12]\n",
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc14bfa1-0b5d-462a-9079-4f1e9378037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = [c for c in X_train.columns if c not in categorical_features]\n",
    "continuous_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2083ed0b-9b65-4bd1-ab92-13161001e729",
   "metadata": {},
   "source": [
    "### 3. Baseline Logistic Regression and Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45f6e58-2f4d-49d7-baf0-478f1540bb9f",
   "metadata": {},
   "source": [
    "#### 3.1 Setting Custom Cross-Validation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e69058-1723-4115-af9c-f03f323256e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "\n",
    "def matrix_to_metrics(mat):\n",
    "    TP = mat[1, 1]\n",
    "    TN = mat[0, 0]\n",
    "    FP = mat[0, 1]\n",
    "    FN = mat[1, 0]\n",
    "    \n",
    "    acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "    prec = TP / (TP + FP) \n",
    "    rec = TP / (TP + FN)\n",
    "    f1_score = 2 * (prec * rec) / (prec + rec)\n",
    "    \n",
    "    return [acc, prec, rec, f1_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea6337b-39a1-40d4-a99d-0ea907e4b86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27b259a-d4c8-458e-b39f-e2d4f84e211a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(data, model_class, model_params, drops, scaler):\n",
    "    result_dict = {} \n",
    "    \n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "    for m in metrics:\n",
    "        result_dict[m] = []\n",
    "\n",
    "    X_train, y_train = data\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # removing correlated columns\n",
    "    X_train = X_train.drop(columns=drops, axis=1)\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for fold in kf.split(X_train): \n",
    "        trn_idx, val_idx = fold\n",
    "        X_trn, X_val = X_train.iloc[trn_idx], X_train.iloc[val_idx] # analysis set \n",
    "        y_trn, y_val = y_train.iloc[trn_idx], y_train.iloc[val_idx] # assessment set\n",
    "        \n",
    "        # scaling\n",
    "        if scaler is not None:   \n",
    "            # previous parameters not retained\n",
    "            X_trn = scaler.fit_transform(X_trn)  \n",
    "            X_val = scaler.transform(X_val) \n",
    "\n",
    "        # model fitting\n",
    "        model = model_class(**model_params)\n",
    "        model.fit(X_trn, y_trn)\n",
    "        \n",
    "        # model evaluation\n",
    "        y_pred = model.predict(X_val)\n",
    "        conf_mat = confusion_matrix(y_val, y_pred)\n",
    "        fold_result = matrix_to_metrics(conf_mat)\n",
    "        for i, val in enumerate(fold_result):\n",
    "            result_dict[metrics[i]].append(round(fold_result[i], 4))\n",
    "            \n",
    "    end_time = time.time() \n",
    "    elapsed_time = end_time - start_time\n",
    "    readable_time = f\"{elapsed_time:.3f} seconds\"\n",
    "    print(readable_time)\n",
    "\n",
    "    for key in result_dict:\n",
    "        result_dict[key].append({'average': round(sum(result_dict[key]) / len(result_dict[key]), 3)})\n",
    "    \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a56572-e485-4840-8927-6c201a6b154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(result_dict):\n",
    "    cols = []\n",
    "    avgs = []\n",
    "    for key in result_dict:\n",
    "        cols.append(key)\n",
    "        avgs.append(result_dict[key][-1]['average'])\n",
    "    return pd.DataFrame({'Metric': cols, 'Average': avgs}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23454f9a-aa35-46dc-87c7-551e3f5849af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(df_dict): \n",
    "    n = len(df_dict)\n",
    "    for idx, item in enumerate(df_dict.items()):\n",
    "        model_name, result = item\n",
    "        if idx == 0:\n",
    "            merged_df = result.rename(columns={'Average': model_name})\n",
    "        else:\n",
    "            merged_df = pd.merge(merged_df, result.rename(columns={'Average': model_name}), on='Metric')\n",
    "\n",
    "    merged_df = merged_df.set_index('Metric')\n",
    "    merged_df['best_model'] = merged_df.idxmax(axis=1)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0e6b4e-5c69-455f-8d41-c31184cdd60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf006c9-f3b4-4909-a3b8-7b0eee75c557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lr(model_dict):\n",
    "    result_dict = {}\n",
    "    for name in model_dict:\n",
    "        print(name, '='* (20-len(name)))\n",
    "        data = model_dict[name]['data']\n",
    "        model_class = model_dict[name]['class']\n",
    "        model_params= model_dict[name]['param']\n",
    "        drops = model_dict[name]['drop']\n",
    "        scaler = model_dict[name]['scaler']\n",
    "        single_result = cross_validate(data, model_class, model_params, drops, scaler)\n",
    "        result_dict[name] = get_summary(single_result)   \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f521017-007f-4f84-b84b-c9c6a15a1605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def customize_scaler(to_scale, to_skip):\n",
    "    scaler = ColumnTransformer(\n",
    "                transformers=[('process', StandardScaler(), to_scale), \n",
    "                    ('skip', 'passthrough', to_skip)])\n",
    "    return scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1826bcdb-3e25-4463-acb2-7f4d5da8370b",
   "metadata": {},
   "source": [
    "#### 3.2 Preliminary Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eceae85-24fe-4f26-a412-1dc240f1d346",
   "metadata": {},
   "outputs": [],
   "source": [
    "skips = ['Complains', 'Tariff Plan', 'Status']\n",
    "uses = [c for c in X_train.columns if c not in skips]\n",
    "uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3141aaa-6a27-4f18-9e75-a0c11a5809f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_scaler = customize_scaler(uses, skips)\n",
    "base_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefdf74c-cb21-4a07-90f1-a2e9e0a9b967",
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_dict = {}\n",
    "vanilla_dict['data'] = [X_train, y_train]\n",
    "vanilla_dict['class'] = LogisticRegression\n",
    "vanilla_dict['param'] = {}\n",
    "vanilla_dict['drop'] = []\n",
    "vanilla_dict['scaler'] = base_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f1d61d-7de4-4e17-9dd2-ef33fbf44f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = {'vanilla': vanilla_dict}\n",
    "vanilla_lr = run_lr(wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554cb072-d5eb-47a7-9f6b-14627fa6f84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_lr['vanilla']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5467ef6-0477-48e2-8e6d-1dd4b74d9814",
   "metadata": {},
   "source": [
    "#### 3.3 Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df1a636-b5a1-4e50-ba6f-d410c51e8339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd810dbd-dc70-4586-b8c0-57e1661869fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_coef(data=[X_train, y_train], scaler=base_scaler):\n",
    "    \n",
    "    X_train, y_train = data\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    lr_coef, stat_coef = [], []\n",
    "    \n",
    "    for fold in kf.split(X_train): \n",
    "        trn_idx, val_idx = fold\n",
    "        X_trn, X_val = X_train.iloc[trn_idx], X_train.iloc[val_idx] # analysis set \n",
    "        y_trn, y_val = y_train.iloc[trn_idx], y_train.iloc[val_idx] # assessment set\n",
    "        \n",
    "        X_trn = scaler.fit_transform(X_trn)  \n",
    "        X_val = scaler.transform(X_val) \n",
    "        \n",
    "        # sklearn\n",
    "        lr = LogisticRegression(penalty='none')\n",
    "        lr.fit(X_trn, y_trn)\n",
    "        lr_coef.append(abs(lr.coef_[0]))\n",
    "\n",
    "        # stat\n",
    "        X_trn_with_const = sm.add_constant(X_trn)  # 절편 추가\n",
    "        stat_lr = sm.Logit(y_trn, X_trn_with_const).fit(disp=0)      \n",
    "        stat_coef.append(np.abs(stat_lr.params[1:]))\n",
    "\n",
    "    mean_lr_coef = np.mean(np.array(lr_coef), axis=0)\n",
    "    mean_stat_coef = np.mean(np.array(stat_coef), axis=0)\n",
    "    \n",
    "    # 결과 출력\n",
    "    coef_df = pd.DataFrame({\n",
    "        'Feature': X_train.columns,\n",
    "        'Sklearn': mean_lr_coef,\n",
    "        'Stat': mean_stat_coef\n",
    "    })\n",
    "    \n",
    "    return coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a7b611-733b-4b7a-a99f-1fb081d349e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = show_coef()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f82dd6e-ff86-4685-add6-5bbdb3ea258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df.sort_values(by='Sklearn', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8980c3c-b892-4d20-b25e-0ed6dde8cc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_candidates = coef_df.sort_values(by='Sklearn', ascending=False)['Feature'][-5:].values.tolist()\n",
    "drop_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed278e0-56bc-477c-aa34-963c7b9f14f0",
   "metadata": {},
   "source": [
    "#### 3.4 Feature Selection Based on CV Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63fcade-de04-4dea-9b8a-dbced3a67e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_dicts = {}\n",
    "\n",
    "for i in range(1, len(drop_candidates)+1):\n",
    "    cur_drop = f'drop_{i}cols'\n",
    "    drop_dicts[cur_drop] = {}\n",
    "    cur_dict = drop_dicts[cur_drop]\n",
    "    cur_dict['data'] = [X_train, y_train]\n",
    "    cur_dict['class'] = LogisticRegression\n",
    "    cur_dict['param'] = {'penalty':'none'}\n",
    "    cur_dict['drop'] = drop_candidates[-i:]\n",
    "    binaries = ['Complains', 'Tariff Plan', 'Status']\n",
    "    skips = [c for c in binaries if c not in cur_dict['drop']]\n",
    "    uses = [c for c in X_train.columns if c not in skips and c not in cur_dict['drop']]\n",
    "    cur_dict['scaler'] = customize_scaler(uses, skips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eb7066-a171-4aac-b35e-78f9f57e5ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_result = run_lr(drop_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357959a6-dced-4dd1-a25b-aea903568036",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models(drop_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a668702-53e9-4d2f-b284-6e5a8726b4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_l2_dicts = {}\n",
    "\n",
    "for i in range(0, 3):\n",
    "    cur_drop = f'drop_{i}cols'\n",
    "    drop_l2_dicts[cur_drop] = {}\n",
    "    cur_dict = drop_l2_dicts[cur_drop]\n",
    "    cur_dict['data'] = [X_train, y_train]\n",
    "    cur_dict['class'] = LogisticRegression\n",
    "    cur_dict['param'] = {}\n",
    "    if i != 0:\n",
    "        cur_dict['drop'] = drop_candidates[-i:]\n",
    "    else:\n",
    "        cur_dict['drop'] = []\n",
    "    binaries = ['Complains', 'Tariff Plan', 'Status']\n",
    "    skips = [c for c in binaries if c not in cur_dict['drop']]\n",
    "    uses = [c for c in X_train.columns if c not in skips and c not in cur_dict['drop']]\n",
    "    cur_dict['scaler'] = customize_scaler(uses, skips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338a975a-771f-40a5-969a-9dc282017b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_l2_result = run_lr(drop_l2_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612c2b7e-f444-49c5-883d-5ee90f716ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models(drop_l2_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a3019a-3878-4ba3-8ae0-f8852b2d79c3",
   "metadata": {},
   "source": [
    "### 4. PCA Feature Generation\n",
    "\t• EDA identified variables with linear relationships.\n",
    "\t• Applied PCA to these variables and combined the resulting feature with the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aad4ba-9c74-4264-9370-2f0a6eb55fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eff91e-b716-4243-abd0-3d8a9bb1a741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_PCA(data, num_comp):\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    pca = PCA(n_components=num_comp)\n",
    "    pcs = pca.fit_transform(scaled_data)\n",
    "    cols = [f'PC{i}' for i in range(1, num_comp+1)]\n",
    "    pca_df = pd.DataFrame(data=pcs, columns=cols)\n",
    "    return pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbd9e7d-7eba-4006-8ba5-05f101d9562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_cols = ['Seconds of Use', 'Frequency of use', 'Frequency of SMS', 'Customer Value']\n",
    "pca_cols = apply_PCA(X_train[corr_cols], 2)\n",
    "other_cols = X_train[[col for col in X_train.columns if col not in corr_cols]]\n",
    "\n",
    "PCA_X_train = pd.concat([pca_cols, other_cols], axis=1)\n",
    "PCA_X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc05129-b2d7-4a67-8a79-148977757c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_wrapper = {}\n",
    "pca_wrapper['pca'] = {}\n",
    "cur_dict = pca_wrapper['pca'] \n",
    "cur_dict['data'] = [PCA_X_train, y_train]\n",
    "cur_dict['class'] = LogisticRegression\n",
    "cur_dict['drop'] = []\n",
    "cur_dict['param'] = {}\n",
    "binaries = ['Complains', 'Tariff Plan', 'Status']\n",
    "skips = binaries + pca_cols.columns.tolist()\n",
    "uses = [c for c in PCA_X_train.columns if c not in skips]\n",
    "cur_dict['scaler'] = customize_scaler(uses, skips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879dbb2e-1ca9-4d73-9440-bf84e594782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_dict['scaler']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c69d429-8043-4494-8e13-1e82999ae8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_result = run_lr(pca_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd87620-b404-4a08-b210-07e9d88cf83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_result['pca']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ac80a2-c126-4b97-b53a-ed852d2081b5",
   "metadata": {},
   "source": [
    "### 4. Spline Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92350552-1fdb-4ae2-9f7a-c9002c106036",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import SplineTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4db629-eade-4ea2-bc0d-32828ce26d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spline_cross_validate(data, model_class, model_params, drops, scaler):\n",
    "    result_dict = {} \n",
    "    \n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "    for m in metrics:\n",
    "        result_dict[m] = []\n",
    "\n",
    "    X_train, y_train = data\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # removing correlated columns\n",
    "    X_train = X_train.drop(columns=drops, axis=1)\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for fold in kf.split(X_train): \n",
    "        trn_idx, val_idx = fold\n",
    "        X_trn, X_val = X_train.iloc[trn_idx], X_train.iloc[val_idx] # analysis set \n",
    "        y_trn, y_val = y_train.iloc[trn_idx], y_train.iloc[val_idx] # assessment set\n",
    "\n",
    "        # spline & scaler transformation\n",
    "        X_trn = scaler.fit_transform(X_trn) \n",
    "        X_val = scaler.transform(X_val) \n",
    "\n",
    "        # 원래 변환 전 칼럼을 드랍해야 함 \n",
    "\n",
    "        # model fitting\n",
    "        model = model_class(**model_params)\n",
    "        model.fit(X_trn, y_trn)\n",
    "        \n",
    "        # model evaluation\n",
    "        y_pred = model.predict(X_val)\n",
    "        conf_mat = confusion_matrix(y_val, y_pred)\n",
    "        fold_result = matrix_to_metrics(conf_mat)\n",
    "        for i, val in enumerate(fold_result):\n",
    "            result_dict[metrics[i]].append(round(fold_result[i], 4))\n",
    "            \n",
    "    end_time = time.time() \n",
    "    elapsed_time = end_time - start_time\n",
    "    readable_time = f\"{elapsed_time:.3f} seconds\"\n",
    "    print(readable_time)\n",
    "\n",
    "    for key in result_dict:\n",
    "        result_dict[key].append({'average': round(sum(result_dict[key]) / len(result_dict[key]), 3)})\n",
    "    \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2611682c-9ee9-4e41-a4d3-7be76267db2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_spline(model_dict):\n",
    "    result_dict = {}\n",
    "    for name in model_dict:\n",
    "        print(name, '='* (20-len(name)))\n",
    "        data = model_dict[name]['data']\n",
    "        model_class = model_dict[name]['class']\n",
    "        model_params= model_dict[name]['param']\n",
    "        drops = model_dict[name]['drop']\n",
    "        scaler = model_dict[name]['scaler']\n",
    "        single_result = spline_cross_validate(data, model_class, model_params, drops, scaler)\n",
    "        result_dict[name] = get_summary(single_result)   \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a8da38-9c60-44e7-9604-fb6ce731e8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "binaries = ['Complains', 'Tariff Plan', 'Status']\n",
    "discretes = [c for c in X_train.columns if c not in binaries and c not in continuous_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eb8cfb-26db-495c-b37a-5ec7bd7a9eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "# spline + scaler\n",
    "spline_scaler_pipeline = Pipeline([\n",
    "    ('spline', SplineTransformer(degree=3, n_knots=4)),  # Spline 변환\n",
    "    ('scaler', StandardScaler()) \n",
    "])\n",
    "\n",
    "spline_scaler = ColumnTransformer(\n",
    "                transformers=[('both', spline_scaler_pipeline, continuous_features), \n",
    "                              ('scaler_only', StandardScaler(), discretes),\n",
    "                              ('skip', 'passthrough', binaries)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f781bd-72e2-43cf-8ce7-c4287b45f718",
   "metadata": {},
   "outputs": [],
   "source": [
    "spline_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad58a211-a517-4e04-8a6a-16ddc31e872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_X = X_train.sample(10, random_state=42)\n",
    "sample_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25463c16-8705-4458-a24d-5099deaae0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spline_sample_X = spline_scaler.fit_transform(sample_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddcaa0e-9989-46ac-abe0-fcc384320b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cfa387-cdc0-48f1-87cd-f73608bad09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(continuous_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc5d070-31cd-43a2-bc13-b107689de5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "spline_sample_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101ab719-c514-4c19-ac97-9f96184370d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(spline_sample_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b79c31f-0116-4af0-889d-3ebb001f994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spline_wrapper = {}\n",
    "spline_wrapper['spline'] = {}\n",
    "cur_dict = spline_wrapper['spline'] \n",
    "cur_dict['data'] = [X_train, y_train]\n",
    "cur_dict['class'] = LogisticRegression\n",
    "cur_dict['drop'] = []\n",
    "cur_dict['param'] = {'max_iter': 300}\n",
    "cur_dict['scaler'] = spline_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddb9b5f-b680-405f-85a5-e27b0c241ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spline_result = run_spline(spline_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e0869f-0621-4cca-9b8c-ca2229019b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "spline_result['spline']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331fb3ee-2659-4cd2-9977-80de0b1ec5ce",
   "metadata": {},
   "source": [
    "### 5. Penalty and Solver Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5a9d09-59a7-4450-a207-2bd88bd4ca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_wrapper = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77a079c-c5b6-4ca1-a1fa-cb77ee27f643",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_wrapper['saga_spline'] = {}    \n",
    "cur_dict = comp_wrapper['saga_spline']\n",
    "cur_dict['data'] = [X_train, y_train]\n",
    "cur_dict['class'] = LogisticRegression\n",
    "cur_dict['drop'] = []\n",
    "cur_dict['param'] = {'solver':'saga', 'max_iter':5000}\n",
    "cur_dict['scaler'] = spline_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20c892b-92cf-42ba-bdac-99eaedb3db4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_wrapper['l1_saga_spline'] = {}    \n",
    "cur_dict = comp_wrapper['l1_saga_spline']\n",
    "cur_dict['data'] = [X_train, y_train]\n",
    "cur_dict['class'] = LogisticRegression\n",
    "cur_dict['drop'] = []\n",
    "cur_dict['param'] = {'penalty':'l1', 'solver':'saga', 'max_iter':5000}\n",
    "cur_dict['scaler'] = spline_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6f91ea-8fa2-4afe-9546-618f95b75b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_results = run_spline(comp_wrapper) # l1_saga_fold3_convergence warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e4cc70-3c46-482f-adb0-04a0ad7f5e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models(comp_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0e2439-9426-41c7-8b2d-ef0e58c4c56f",
   "metadata": {},
   "source": [
    "### 5. Handling Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19c4203-bce2-4d0c-afdf-f1e398ec931a",
   "metadata": {},
   "source": [
    "#### 5.1 SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce33ae6-684e-4db3-85cd-46c3ab8766c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline-Wrapped Code for Reference\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.model_selection import cross_validate as sk_cv\n",
    "\n",
    "pipe = Pipeline(steps = [('smote', SMOTENC(categorical_features, random_state=42)), \n",
    "                      ('base_scaler', base_scaler),\n",
    "                      ('logisticregression', LogisticRegression())])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# cross validation using intra-fold sampling\n",
    "sk_cv(pipe, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6abc708-feb2-419d-9dd1-364f66e8aa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dae3758-4a38-4cdb-be3d-7826a974ea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.array([0.83168317, 0.82630273, 0.88337469, 0.85111663, 0.85111663]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2913640a-440c-4501-9781-bc569bc9971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote_cross_validate(data, model_class, model_params, drops, scaler):\n",
    "    result_dict = {} \n",
    "    \n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "    for m in metrics:\n",
    "        result_dict[m] = []\n",
    "\n",
    "    X_train, y_train = data\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # removing correlated columns\n",
    "    X_train = X_train.drop(columns=drops, axis=1)\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for fold in kf.split(X_train): \n",
    "        \n",
    "        trn_idx, val_idx = fold\n",
    "        X_trn, X_val = X_train.iloc[trn_idx], X_train.iloc[val_idx] # analysis set \n",
    "        y_trn, y_val = y_train.iloc[trn_idx], y_train.iloc[val_idx] # assessment set\n",
    "\n",
    "        # smote applying on only training set\n",
    "        smote_nc = SMOTENC(categorical_features, random_state=42)\n",
    "        X_trn, y_trn = smote_nc.fit_resample(X_trn, y_trn)\n",
    "        \n",
    "        # scaling\n",
    "        # previous parameters not retained\n",
    "        X_trn = scaler.fit_transform(X_trn) \n",
    "        X_val = scaler.transform(X_val) \n",
    "\n",
    "        # model fitting\n",
    "        model = model_class(**model_params)\n",
    "        model.fit(X_trn, y_trn)\n",
    "        \n",
    "        # model evaluation\n",
    "        y_pred = model.predict(X_val)\n",
    "        conf_mat = confusion_matrix(y_val, y_pred)\n",
    "        fold_result = matrix_to_metrics(conf_mat)\n",
    "        for i, val in enumerate(fold_result):\n",
    "            result_dict[metrics[i]].append(round(fold_result[i], 4))\n",
    "            \n",
    "    end_time = time.time() \n",
    "    elapsed_time = end_time - start_time\n",
    "    readable_time = f\"{elapsed_time:.3f} seconds\"\n",
    "    print(readable_time)\n",
    "\n",
    "    for key in result_dict:\n",
    "        result_dict[key].append({'average': round(sum(result_dict[key]) / len(result_dict[key]), 3)})\n",
    "    \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722bcf0a-4a34-4f1c-8307-513b5e0e3d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_smote(model_dict):\n",
    "    result_dict = {}\n",
    "    for name in model_dict:\n",
    "        print(name, '='* (20-len(name)))\n",
    "        data = model_dict[name]['data']\n",
    "        model_class = model_dict[name]['class']\n",
    "        model_params= model_dict[name]['param']\n",
    "        drops = model_dict[name]['drop']\n",
    "        scaler = model_dict[name]['scaler']\n",
    "        single_result = smote_cross_validate(data, model_class, model_params, drops, scaler)\n",
    "        result_dict[name] = get_summary(single_result)   \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4653281d-1321-457c-895c-71b29529b1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_wrapper = {'smote': {}}\n",
    "cur_dict = smote_wrapper['smote']\n",
    "cur_dict['data'] = [X_train, y_train]\n",
    "cur_dict['class'] = LogisticRegression\n",
    "cur_dict['param'] = {'solver':'saga', 'max_iter':5000}\n",
    "cur_dict['drop'] = []\n",
    "cur_dict['scaler'] = base_scaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165d1c73-97fd-483e-9525-42cee05ab7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_wrapper['smote_spline'] = {}\n",
    "cur_dict = smote_wrapper['smote_spline']\n",
    "cur_dict['data'] = [X_train, y_train]\n",
    "cur_dict['class'] = LogisticRegression\n",
    "cur_dict['param'] = {'solver':'saga', 'max_iter':5000}\n",
    "cur_dict['drop'] = []\n",
    "cur_dict['scaler'] = spline_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c019db-7574-44ab-b440-69082d04a1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_result = run_smote(smote_wrapper) \n",
    "compare_models(smote_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4c7a3e-defc-42cf-9300-16282a45eec0",
   "metadata": {},
   "source": [
    "#### 5.2 Model Weight Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5c037d-393c-47a0-9655-e05b35fa5747",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_wrapper = {}\n",
    "weight_wrapper['weight'] = {}\n",
    "cur_dict = weight_wrapper['weight'] \n",
    "cur_dict['data'] = [X_train, y_train]\n",
    "cur_dict['class'] = LogisticRegression\n",
    "cur_dict['drop'] = []\n",
    "cur_dict['param'] = {'solver':'saga', 'max_iter':5000, 'class_weight':'balanced'}\n",
    "binaries = ['Complains', 'Tariff Plan', 'Status']\n",
    "cur_dict['scaler'] = base_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6190a8f6-3d21-4a01-9d3d-52203265fda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_smote_wrapper = {}\n",
    "weight_smote_wrapper['smote'] = {}\n",
    "cur_dict = weight_smote_wrapper['smote'] \n",
    "cur_dict['data'] = [X_train, y_train]\n",
    "cur_dict['class'] = LogisticRegression\n",
    "cur_dict['drop'] = []\n",
    "cur_dict['param'] = {'solver':'saga', 'max_iter':5000, 'class_weight':'balanced'}\n",
    "binaries = ['Complains', 'Tariff Plan', 'Status']\n",
    "cur_dict['scaler'] = base_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d90ced3-aebb-4f05-af2f-a1083e0ebc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_only = run_lr(weight_wrapper)\n",
    "weight_only['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5799d4-7180-4e10-851e-bf38f3548048",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_smote = run_smote(weight_smote_wrapper)\n",
    "weight_smote['smote']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a517b62-b587-4240-ba69-2277610444e5",
   "metadata": {},
   "source": [
    "### 6. Final Results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb503f9-3aab-4237-aee2-859771f06126",
   "metadata": {},
   "source": [
    "#### 6.1 Summary of CV Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420404b0-12af-4973-a321-b65dfdae866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = compare_models(drop_l2_result).drop(columns=['best_model'])\n",
    "drops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c792b3fd-6869-4fde-8e7b-3ca4d2bb1a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_adj = compare_models(comp_results).drop(columns=['best_model'])\n",
    "model_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13c5d37-869a-4d3e-a674-3e06781e2e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "smotes = compare_models(smote_result).drop(columns=['best_model'])\n",
    "smotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7972254-3fe3-4681-ad7f-4616a1bff457",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {'vanilla': vanilla_lr['vanilla'], \n",
    "          'pca': pca_result['pca'],\n",
    "          'spline': spline_result['spline'], \n",
    "         'weight': weight_only['weight'], 'smote_weight': weight_smote['smote']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de927a7-d039-45ac-bbb2-87c4d4cb2ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.DataFrame()\n",
    "for key, df in df_dict.items():\n",
    "    df_renamed = df.rename(columns={'Average': key})\n",
    "    if merged_df.empty:\n",
    "        merged_df = df_renamed\n",
    "    else:\n",
    "        merged_df = pd.merge(merged_df, df_renamed, on='Metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702fbc5b-7fbe-41f7-8a9b-0a02386fe5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8749dec1-4d0e-4e0e-9693-ac511b66325d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af0f8e8-a62a-48f9-a46b-7b7e4fd8915a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "dfs = [merged_df, drops, model_adj, smotes]  # 합치려는 데이터프레임 리스트\n",
    "merged_df_final = reduce(lambda left, right: pd.merge(left, right, on='Metric'), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1531a0ac-5500-4c78-b7a9-a62e87937be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_final.set_index('Metric', inplace=True)\n",
    "merged_df_final['best_model'] = merged_df_final.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc6a042-4fc9-40a5-a80c-7f8832ba80ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154ef6c0-e16a-4674-9a86-b91e6a3fa06a",
   "metadata": {},
   "source": [
    "#### 6.2 Test Set Logistic Regression Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d5826a-0515-4236-911d-30b6ffe66ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_wrapper = {'saga_spline': {}}\n",
    "cur_dict = final_wrapper['saga_spline']\n",
    "cur_dict['data'] = [X_train, y_train, X_test, y_test]\n",
    "cur_dict['class'] = LogisticRegression\n",
    "cur_dict['drop'] = []\n",
    "cur_dict['param'] = {'solver':'saga', 'max_iter':5000}\n",
    "cur_dict['scaler'] = spline_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9476f2-1490-424b-9561-30beffa3c823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, model_class, model_params, drops, scaler):\n",
    "    result_dict = {} \n",
    "    \n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "    for m in metrics:\n",
    "        result_dict[m] = []\n",
    "\n",
    "    [X_train, y_train, X_test, y_test] = data\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    X_train = scaler.fit_transform(X_train)  \n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    model = model_class(**model_params)\n",
    "    model.fit(X_train, y_train)\n",
    "        \n",
    "    y_pred = model.predict(X_test)\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    final_result = matrix_to_metrics(conf_mat)\n",
    "    for i, val in enumerate(final_result):\n",
    "        result_dict[metrics[i]].append(round(final_result[i], 4))\n",
    "        \n",
    "    end_time = time.time() \n",
    "    elapsed_time = end_time - start_time\n",
    "    readable_time = f\"{elapsed_time:.3f} seconds\"\n",
    "    print(readable_time)\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7439aae3-65d6-4a7c-abce-6c54f3801852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model_dict):\n",
    "    result_dict = {}\n",
    "    for name in model_dict:\n",
    "        print(name, '='* (20-len(name)))\n",
    "        data = model_dict[name]['data']\n",
    "        model_class = model_dict[name]['class']\n",
    "        model_params= model_dict[name]['param']\n",
    "        drops = model_dict[name]['drop']\n",
    "        scaler = model_dict[name]['scaler']\n",
    "        single_result = train(data, model_class, model_params, drops, scaler)\n",
    "        result_dict[name] = single_result \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593e285d-770e-4c9f-877f-e07b525e88f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = run(final_wrapper)['saga_spline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b583dcd-371a-4d4c-a289-31bb784dc452",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(final_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
